{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrJj5oA-9Lk9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import pickle\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/augmented_diverse_structure.pkl\", \"rb\") as f:\n",
        "    augmented_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "iZgW49WP9mHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lU0KoXJmPt4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a616dfe8-da5a-4203-eb2d-2ecd554c629a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Speech-NER/train.pkl\", 'rb') as file:\n",
        "    train = pickle.load(file)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Speech-NER/test.pkl\", 'rb') as file:\n",
        "    test = pickle.load(file)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Speech-NER/aug.pkl\", 'rb') as file:\n",
        "    aug = pickle.load(file)"
      ],
      "metadata": {
        "id": "_ynrD9kdPvR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_data = [[], []]\n",
        "for i in range(len(train[0])):\n",
        "  if train[1][i] != []:\n",
        "    seed_data[0].append(train[0][i])\n",
        "    seed_data[1].append(train[1][i])"
      ],
      "metadata": {
        "id": "6fu_Z0eRQ5B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "num_to_words = {\n",
        "    '0': 'zero', '1': 'one', '2': 'two', '3': 'three', '4': 'four',\n",
        "    '5': 'five', '6': 'six', '7': 'seven', '8': 'eight', '9': 'nine'\n",
        "}\n",
        "\n",
        "def generate_credit():\n",
        "    if random.random() > 0.3:\n",
        "      groups = [''.join(str(random.randint(0, 9)) for _ in range(4)) for _ in range(4)]\n",
        "    else:\n",
        "      groups = [' '.join(num_to_words[str(random.randint(0, 9))] for _ in range(4)) for _ in range(4)]\n",
        "    return '-'.join(groups)\n",
        "\n",
        "def get_nric_prefix():\n",
        "    prefixes = [\"S\", \"T\", \"F\", \"G\"]\n",
        "    return random.choice(prefixes)\n",
        "\n",
        "def calculate_nric_suffix(prefix, digits):\n",
        "    weights = [2, 7, 6, 5, 4, 3, 2]\n",
        "    sum_val = sum(int(d) * w for d, w in zip(digits, weights))\n",
        "    if prefix in [\"T\", \"G\"]:\n",
        "        sum_val += 4\n",
        "    if prefix in [\"F\", \"G\"]:\n",
        "        mapping = \"XWUTRQPONMLK\"\n",
        "    else:\n",
        "        mapping = \"JZIHGFEDCBA\"\n",
        "\n",
        "    return mapping[sum_val % 11]\n",
        "\n",
        "def generate_nric():\n",
        "    prefix = get_nric_prefix()\n",
        "    digits = ''.join(str(random.randint(0, 9)) for _ in range(7))\n",
        "    suffix = calculate_nric_suffix(prefix, digits)\n",
        "    if random.random() > 0.7:\n",
        "      digits = \" \".join(num_to_words[d] for d in digits)\n",
        "      return f\"{prefix} {digits} {suffix}\"\n",
        "    return f\"{prefix}{digits}{suffix}\"\n",
        "\n",
        "def generate_passport():\n",
        "    if random.random() > 0.7:\n",
        "      return f\"K {' '.join(num_to_words[str(random.randint(0, 9))] for _ in range(7))} {random.choice('ABCDEFGHIJKLMNOPQRSTUVWXYZ')}\"\n",
        "    return f\"K{''.join(str(random.randint(0, 9)) for _ in range(7))}{random.choice('ABCDEFGHIJKLMNOPQRSTUVWXYZ')}\"\n",
        "\n",
        "def generate_phone():\n",
        "    start_digit = random.choice(['6', '8', '9'])\n",
        "    rest_digits = ''.join(str(random.randint(0, 9)) for _ in range(3))\n",
        "    second_group = ''.join(str(random.randint(0, 9)) for _ in range(4))\n",
        "    if random.random() > 0.7:\n",
        "      start_digit = num_to_words[start_digit]\n",
        "      rest_digits = \" \".join(num_to_words[d] for d in rest_digits)\n",
        "      second_group = \" \".join(num_to_words[d] for d in second_group)\n",
        "      return f\"{start_digit} {rest_digits}-{second_group}\"\n",
        "    return f\"{start_digit}{rest_digits}-{second_group}\"\n",
        "\n",
        "def generate_email():\n",
        "    if random.random() > 0.45:\n",
        "      user =  ' '.join(generate_person().split()[0]) + ''.join(random.choice('abcdefghijklmnopqrstuvwxyz0123456789') for _ in range(4))\n",
        "    else:\n",
        "      user =  (generate_person().split()[0]) + ''.join(random.choice('abcdefghijklmnopqrstuvwxyz0123456789') for _ in range(4))\n",
        "\n",
        "    domain = random.choice([\n",
        "    \"gmail.com\", \"mailbox.org\", \"protonmail.com\", \"outlook.com\", \"hotmail.com\", \"yahoo.com\", \"icloud.com\",\n",
        "    \"aol.com\", \"zoho.com\", \"gmx.com\", \"yandex.com\", \"mail.com\", \"fastmail.com\", \"hushmail.com\", \"tutanota.com\",\n",
        "    \"inbox.com\", \"me.com\", \"mac.com\", \"aim.com\", \"lycos.com\", \"rediffmail.com\", \"juno.com\", \"mymail.com\",\n",
        "    \"runbox.com\", \"mailfence.com\", \"posteo.net\", \"vivaldi.net\", \"mail.ru\", \"sbcglobal.net\", \"bellsouth.net\",\n",
        "    \"verizon.net\", \"earthlink.net\", \"comcast.net\", \"cox.net\", \"charter.net\", \"frontier.com\", \"netzero.net\",\n",
        "    \"att.net\", \"zoho.eu\", \"prodigy.net\", \"rogers.com\", \"shaw.ca\", \"telus.net\", \"sympatico.ca\", \"web.de\",\n",
        "    \"mail.bg\", \"123.com\", \"bigpond.com\", \"optusnet.com.au\", \"ozemail.com.au\", \"internode.on.net\",\n",
        "    \"tpg.com.au\", \"iinet.net.au\", \"dodo.com.au\", \"vodafone.com.au\", \"slingshot.co.nz\", \"xtra.co.nz\",\n",
        "    \"spark.co.nz\", \"clear.net.nz\", \"orcon.net.nz\", \"talktalk.net\", \"btinternet.com\", \"virginmedia.com\",\n",
        "    \"blueyonder.co.uk\", \"sky.com\", \"ntlworld.com\", \"eircom.net\", \"o2.ie\", \"orange.fr\", \"free.fr\", \"sfr.fr\",\n",
        "    \"laposte.net\", \"wanadoo.fr\", \"neuf.fr\", \"aliceadsl.fr\", \"libero.it\", \"virgilio.it\", \"tiscali.it\",\n",
        "    \"tin.it\", \"tele2.it\", \"vodafone.it\", \"fastwebnet.it\", \"poste.it\", \"iol.it\", \"tim.it\", \"alice.it\",\n",
        "    \"netcabo.pt\", \"clix.pt\", \"mail.pt\", \"tvtel.pt\", \"netmadeira.com\", \"brisanet.pt\", \"sapomail.net\",\n",
        "    \"orange.es\", \"telefonica.net\", \"movistar.es\", \"terra.es\", \"wanadoo.es\", \"ya.com\", \"jazzfree.com\",\n",
        "    \"mundo-r.com\", \"ono.com\", \"vodafone.es\", \"telefÃ³nica.es\", \"euskaltel.com\", \"optimum.net\", \"optonline.net\"\n",
        "])\n",
        "    return f\"{user}@{domain}\"\n",
        "\n",
        "def generate_car():\n",
        "    series = random.choice([chr(i) for i in range(65, 91) if chr(i) not in [\"I\", \"O\"]])\n",
        "    number = ''.join(str(random.randint(0, 9)) for _ in range(4))\n",
        "    checksum = random.choice([chr(i) for i in range(65, 91) if chr(i) not in [\"F\", \"I\", \"N\", \"O\", \"Q\", \"V\", \"W\"]])\n",
        "    return f\"S{series}{number}{checksum}\"\n",
        "\n",
        "def generate_bank():\n",
        "    parts = [\n",
        "        ''.join(str(random.randint(0, 9)) for _ in range(3)),\n",
        "        ''.join(str(random.randint(0, 9)) for _ in range(5)),\n",
        "        str(random.randint(0, 9))\n",
        "    ]\n",
        "    if random.random() > 0.7:\n",
        "      string = '-'.join(parts)\n",
        "      new_string = \"\"\n",
        "      for i in string:\n",
        "        if i in num_to_words:\n",
        "            new_string = new_string + num_to_words[i] + \" \"\n",
        "      return new_string\n",
        "    return '-'.join(parts)\n",
        "\n",
        "def generate_person():\n",
        "  person_list = [ \"aaliyah johnson\", \"aaron nguyen\", \"abdul rahman\", \"abigail cohen\", \"aditya gupta\",\n",
        "    \"aisha brown\", \"alberto gomez\", \"alexandra petrova\", \"ali hassan\", \"alice zhang\",\n",
        "    \"alicia ramirez\", \"alina schmidt\", \"amara osei\", \"amelia thompson\", \"amir khan\",\n",
        "    \"anastasia ivanova\", \"anders johansson\", \"andrea rossi\", \"andres martinez\", \"angela williams\",\n",
        "    \"anika patel\", \"anna smith\", \"anwar bakir\", \"aria kim\", \"ariana gonzalez\",\n",
        "    \"arjun reddy\", \"asher green\", \"aya tanaka\", \"ayesha malik\", \"aziz youssef\",\n",
        "    \"barbara mitchell\", \"benjamin lee\", \"binh tran\", \"boris ivanov\", \"brandon walker\",\n",
        "    \"brenda lopez\", \"brian o'connor\", \"camila hernandez\", \"carlos silva\", \"carmen reyes\",\n",
        "    \"catherine white\", \"cheng li\", \"chiara bianchi\", \"chloe wilson\", \"christina nielsen\",\n",
        "    \"claudia garcia\", \"colin murphy\", \"constance mbatha\", \"cristina neves\", \"dahlia ahmed\",\n",
        "    \"daniel brown\", \"dariusz lewandowski\", \"david smith\", \"deborah green\", \"deepak kumar\",\n",
        "    \"diego rodriguez\", \"dmitri mikhailov\", \"dominique dupont\", \"dung nguyen\", \"eduardo santos\",\n",
        "    \"elena petrova\", \"elias fischer\", \"elizabeth johnson\", \"ella roberts\", \"emanuel mendes\",\n",
        "    \"emilia romero\", \"emily jones\", \"emma clark\", \"enrique ortega\", \"erin o'brien\",\n",
        "    \"esther kim\", \"ethan wang\", \"eva nielsen\", \"fahad hassan\", \"fatima bint abdullah\",\n",
        "    \"fernando garcia\", \"fiona murray\", \"francesco ricci\", \"gabriel rodriguez\", \"georgia baker\",\n",
        "    \"gianna mancini\", \"grace davis\", \"gregory adams\", \"guadalupe flores\", \"habiba al-mahdi\",\n",
        "    \"hana yamamoto\", \"hans meier\", \"hassan abdullah\", \"heather wilson\", \"hector ramirez\",\n",
        "    \"helena ivanova\", \"henry chen\", \"hugo rodrigues\", \"ibrahim khalid\", \"iggy taylor\",\n",
        "    \"imran khan\", \"inaya sheikh\", \"ingrid larsen\", \"irina petrov\", \"isaac king\",\n",
        "    \"isabel garcia\", \"isabella rossi\", \"ivan novak\", \"jackson brown\", \"jacob cohen\",\n",
        "    \"jaime diaz\", \"jamal williams\", \"jasmine patel\", \"jasper lee\", \"jayden clark\",\n",
        "    \"jennifer miller\", \"jessica wilson\", \"jia li\", \"joana mendes\", \"joel kim\",\n",
        "    \"johann schmidt\", \"john o'connor\", \"jose luis gonzalez\", \"josÃ© martÃ­nez\", \"joseph white\",\n",
        "    \"josue rivera\", \"juan perez\", \"julia weber\", \"julian meyer\", \"julie andrews\",\n",
        "    \"karen davis\", \"karim abdullah\", \"katerina petrova\", \"katherine lee\", \"katie brown\",\n",
        "    \"kevin mccarthy\", \"khadija ali\", \"kiara washington\", \"kirsten hansen\", \"kofi boakye\",\n",
        "    \"krishna rao\", \"kumar bhatt\", \"laila hassan\", \"larissa almeida\", \"laura johnson\",\n",
        "    \"leah kim\", \"leandro silva\", \"leo martin\", \"leon wu\", \"leona fox\",\n",
        "    \"leslie torres\", \"liam o'brien\", \"lila johnson\", \"lina schmidt\", \"linda lopez\",\n",
        "    \"logan smith\", \"lorenzo de luca\", \"lucas brown\", \"lucia garcia\", \"ludmila sokolova\",\n",
        "    \"luisa fernandez\", \"lukas novak\", \"madison clark\", \"magnus johansson\", \"mahmoud al-amin\",\n",
        "    \"maria fernandez\", \"mariah jones\", \"marina volkov\", \"mario rossi\", \"markus schneider\",\n",
        "    \"marta costa\", \"martin brown\", \"maryam khan\", \"mateo lopez\", \"matteo ricci\",\n",
        "    \"maya patel\", \"megan turner\", \"mei li\", \"melissa johnson\", \"mia davis\",\n",
        "    \"micah anderson\", \"michael young\", \"michelle kim\", \"miguel rodriguez\", \"mikhail novikov\",\n",
        "    \"mina akhtar\", \"mohammed al-saadi\", \"mohammad rahman\", \"molly brown\", \"monica flores\",\n",
        "    \"muhammad ali\", \"nadia ibrahim\", \"naomi tanaka\", \"natalia romanov\", \"nathaniel smith\",\n",
        "    \"neha jain\", \"nicolas fernandez\", \"noah walker\", \"nora schmidt\", \"olivia taylor\",\n",
        "    \"omar gonzalez\", \"oscar morales\", \"pablo rodriguez\", \"paloma garcia\", \"parker johnson\",\n",
        "    \"patricia evans\", \"patrick murphy\", \"paul smith\", \"paula souza\", \"pedro mendes\",\n",
        "    \"peter brown\", \"priya singh\", \"qasim ali\", \"quinn o'neill\", \"rachel smith\",\n",
        "    \"rahul desai\", \"raj kumar\", \"ramona lopez\", \"rashid ahmed\", \"rebecca williams\",\n",
        "    \"renato de souza\", \"ricardo torres\", \"roberto marino\", \"robin taylor\", \"rosa ramirez\",\n",
        "    \"ryan davis\", \"sabrina khan\", \"sahil mehta\", \"samuel moore\", \"sanjay kumar\",\n",
        "    \"sarah lee\", \"sasha petrov\", \"savannah johnson\", \"sebastian garcia\", \"selena fernandez\",\n",
        "    \"serena jones\", \"shahzad malik\", \"shelly brown\", \"sophia white\", \"sophie harris\",\n",
        "    \"stefan popov\", \"steven wong\", \"sumit patel\", \"susana mendez\", \"syed ali\",\n",
        "    \"tahira abdi\", \"tamara johnson\", \"tara o'neill\", \"tariq hasan\", \"taylor miller\",\n",
        "    \"tereza mendes\", \"terry jones\", \"thomas white\", \"thuy nguyen\", \"tian zhang\",\n",
        "    \"tina williams\", \"timothy brown\", \"tom johnson\", \"tshepo nkosi\", \"usman khan\",\n",
        "    \"valeria rossi\", \"vanessa davis\", \"vera ivanova\", \"victor silva\", \"victoria brown\",\n",
        "    \"vincent leclerc\", \"vivek sharma\", \"wang wei\", \"wen li\", \"william smith\",\n",
        "    \"winona johnson\", \"xavier garcia\", \"yasmin ali\", \"yevgeny petrov\", \"yolanda hernandez\",\n",
        "    \"youssef el-khoury\", \"yuki nakamura\", \"zainab khan\", \"zarina ahmed\", \"zoe clark\"\n",
        "]\n",
        "  return random.choice(person_list)\n",
        "\n",
        "def generate_org():\n",
        "  org_list = [\n",
        "    \"Google\", \"Microsoft\", \"Apple\", \"Amazon\", \"Facebook\", \"IBM\", \"Intel\", \"Cisco\", \"Oracle\", \"HP\",\n",
        "    \"Dell\", \"Samsung\", \"Sony\", \"LG\", \"Panasonic\", \"Nokia\", \"Siemens\", \"Tesla\", \"SpaceX\", \"Alibaba\",\n",
        "    \"Tencent\", \"Baidu\", \"Huawei\", \"Xiaomi\", \"PayPal\", \"Adobe\", \"Salesforce\", \"Netflix\", \"Spotify\",\n",
        "    \"Uber\", \"Airbnb\", \"Lyft\", \"Shopify\", \"Pinterest\", \"LinkedIn\", \"Snapchat\", \"Twitter\", \"WeWork\",\n",
        "    \"Stripe\", \"Square\", \"Dropbox\", \"Slack\", \"Zoom\", \"Reddit\", \"TikTok\", \"Twitch\", \"Snap\", \"Qualcomm\",\n",
        "    \"Nvidia\", \"AMD\", \"Accenture\", \"Adobe Systems\", \"Amazon Web Services\", \"American Express\", \"AOL\",\n",
        "    \"AT&T\", \"Autodesk\", \"Boeing\", \"Broadcom\", \"Capgemini\", \"CGI\", \"Cognizant\", \"Comcast\", \"CrowdStrike\",\n",
        "    \"Dell Technologies\", \"eBay\", \"Electronic Arts\", \"Ericsson\", \"Expedia\", \"Ford Motor Company\", \"Fujitsu\",\n",
        "    \"Garmin\", \"General Electric\", \"General Motors\", \"GitHub\", \"GoDaddy\", \"Hewlett Packard Enterprise\",\n",
        "    \"Hitachi\", \"Honeywell\", \"Hyundai\", \"Infosys\", \"Intuit\", \"J.P. Morgan\", \"JD.com\", \"Juniper Networks\",\n",
        "    \"Lenovo\", \"Logitech\", \"Mastercard\", \"McAfee\", \"Micron Technology\", \"Nasdaq\", \"NCR Corporation\", \"Nokia Corporation\",\n",
        "    \"Northrop Grumman\", \"NTT Data\", \"Okta\", \"Palantir\", \"Palo Alto Networks\", \"Paytm\", \"Qualys\", \"Rakuten\",\n",
        "    \"Raytheon Technologies\", \"SAP\", \"Seagate Technology\", \"ServiceNow\", \"Siemens AG\", \"SoftBank Group\", \"Sony Corporation\",\n",
        "    \"Square Inc.\", \"Symantec\", \"Synopsys\", \"Tech Mahindra\", \"Texas Instruments\", \"Thales Group\", \"T-Mobile\",\n",
        "    \"Toshiba\", \"Toyota\", \"Uber Technologies\", \"Verizon\", \"Visa\", \"VMware\", \"Western Digital\", \"Wipro\",\n",
        "    \"Workday\", \"Xerox\", \"Yahoo\", \"Yandex\", \"Zillow\", \"ZTE\", \"Zoom Video Communications\", \"Zscaler\",\n",
        "    \"Samsung Electronics\", \"LG Electronics\", \"Foxconn\", \"Tencent Holdings\", \"Alibaba Group\", \"Baidu Inc.\",\n",
        "    \"JD.com Inc.\", \"NetEase\", \"Sina Corporation\", \"Weibo Corporation\", \"Xiaomi Corporation\", \"Meituan Dianping\",\n",
        "    \"Didi Chuxing\", \"ByteDance\", \"Pinduoduo\", \"Sogou\", \"58.com\", \"China Mobile\", \"China Telecom\", \"China Unicom\"\n",
        "]\n",
        "\n",
        "  return random.choice(org_list)\n",
        "\n",
        "def generate_cardinal():\n",
        "  cardinal_list = [\n",
        "    \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\",\n",
        "    \"seventeen\", \"eighteen\", \"nineteen\", \"twenty\", \"twenty-one\", \"twenty-two\", \"twenty-three\", \"twenty-four\", \"twenty-five\", \"twenty-six\", \"twenty-seven\",\n",
        "    \"twenty-eight\", \"twenty-nine\", \"thirty\", \"thirty-one\", \"thirty-two\", \"thirty-three\", \"thirty-four\", \"thirty-five\", \"thirty-six\", \"thirty-seven\",\n",
        "    \"thirty-eight\", \"thirty-nine\", \"forty\", \"forty-one\", \"forty-two\", \"forty-three\", \"forty-four\", \"forty-five\", \"forty-six\", \"forty-seven\", \"forty-eight\",\n",
        "    \"forty-nine\", \"fifty\"\n",
        "]\n",
        "\n",
        "  return random.choice(cardinal_list)\n",
        "\n",
        "def generate_gpe():\n",
        "  gpe_list = [\n",
        "      \"singapore\", \"malaysia\", \"indonesia\", \"philippines\", \"vietnam\", \"laos\", \"cambodia\", \"myanmar\", \"brunei\", \"east_timor\",\n",
        "      \"thailand\", \"india\", \"china\", \"japan\", \"south_korea\", \"north_korea\", \"taiwan\", \"hong_kong\", \"macau\", \"mongolia\",\n",
        "      \"australia\", \"new_zealand\", \"papua_new_guinea\", \"fiji\", \"tonga\", \"samoa\", \"vanuatu\", \"solomon_islands\", \"palau\", \"micronesia\",\n",
        "      \"nauru\", \"kiribati\", \"marshall_islands\", \"tuvalu\", \"maldives\", \"sri_lanka\", \"bangladesh\", \"nepal\", \"bhutan\", \"pakistan\",\n",
        "      \"afghanistan\", \"iran\", \"iraq\", \"syria\", \"lebanon\", \"jordan\", \"israel\", \"saudi_arabia\", \"uae\", \"qatar\", \"kuwait\",\n",
        "      \"bahrain\", \"united_states\", \"canada\", \"mexico\", \"brazil\", \"argentina\", \"chile\", \"peru\", \"colombia\", \"venezuela\",\n",
        "      \"uruguay\", \"paraguay\", \"bolivia\", \"ecuador\", \"guyana\", \"suriname\", \"france\", \"germany\", \"united_kingdom\", \"italy\",\n",
        "      \"spain\", \"portugal\", \"netherlands\", \"belgium\", \"switzerland\", \"austria\", \"sweden\", \"norway\", \"denmark\", \"finland\",\n",
        "      \"iceland\", \"ireland\", \"greece\", \"turkey\", \"russia\", \"ukraine\", \"belarus\", \"poland\", \"czech_republic\", \"slovakia\",\n",
        "      \"hungary\", \"romania\", \"bulgaria\", \"serbia\", \"croatia\", \"slovenia\", \"bosnia_and_herzegovina\", \"montenegro\", \"macedonia\",\n",
        "      \"albania\", \"kosovo\", \"luxembourg\", \"monaco\", \"andorra\", \"liechtenstein\", \"san_marino\", \"vatican_city\", \"morocco\",\n",
        "      \"algeria\", \"tunisia\", \"libya\", \"egypt\", \"sudan\", \"south_sudan\", \"ethiopia\", \"somalia\", \"kenya\", \"uganda\",\n",
        "      \"rwanda\", \"burundi\", \"tanzania\", \"zambia\", \"zimbabwe\", \"mozambique\", \"botswana\", \"namibia\", \"south_africa\", \"lesotho\",\n",
        "      \"swaziland\", \"angola\", \"drc\", \"congo\", \"gabon\", \"equatorial_guinea\", \"cameroon\", \"nigeria\", \"niger\", \"mali\",\n",
        "      \"chad\", \"central_african_republic\", \"sudan\", \"eritrea\", \"djibouti\", \"madagascar\", \"comoros\", \"seychelles\", \"mauritius\",\n",
        "      \"mauritania\", \"senegal\", \"gambia\", \"guinea\", \"guinea_bissau\", \"sierra_leone\", \"liberia\", \"cote_d'ivoire\", \"ghana\",\n",
        "      \"togo\", \"benin\", \"burkina_faso\", \"mali\", \"greenland\", \"iceland\", \"barbados\", \"bahamas\", \"cuba\", \"jamaica\",\n",
        "      \"haiti\", \"dominican_republic\", \"puerto_rico\", \"trinidad_and_tobago\", \"saint_lucia\", \"saint_vincent_and_the_grenadines\", \"grenada\",\n",
        "      \"saint_kitts_and_nevis\", \"antigua_and_barbuda\", \"dominica\", \"brazil\", \"colombia\", \"argentina\", \"chile\", \"peru\",\n",
        "      \"venezuela\", \"uruguay\", \"paraguay\", \"bolivia\", \"ecuador\", \"guyana\", \"suriname\", \"french_guiana\", \"falkland_islands\",\n",
        "      \"greenland\", \"iceland\", \"barbados\", \"bahamas\", \"cuba\", \"jamaica\", \"haiti\", \"dominican_republic\", \"puerto_rico\",\n",
        "      \"trinidad_and_tobago\", \"saint_lucia\", \"saint_vincent_and_the_grenadines\", \"grenada\", \"saint_kitts_and_nevis\", \"antigua_and_barbuda\",\n",
        "      \"dominica\", \"antarctica\", \"arctic\", \"the_amazon\", \"sahara_desert\", \"mount_everest\", \"great_barrier_reef\", \"niagara_falls\",\n",
        "      \"grand_canyon\", \"victoria_falls\", \"serengeti_national_park\", \"kruger_national_park\", \"banff_national_park\", \"yosemite_national_park\",\n",
        "      \"yellowstone_national_park\", \"galapagos_islands\", \"machu_picchu\", \"angkor_wat\", \"the_great_wall_of_china\", \"petra\",\n",
        "      \"taj_mahal\", \"stonehenge\", \"eiffel_tower\", \"colosseum\", \"sydney_opera_house\", \"burj_khalifa\"\n",
        "  ]\n",
        "  return random.choice(gpe_list)\n",
        "\n",
        "def generate_time():\n",
        "  time_list = [\n",
        "    \"one day one night\", \"two days one night\", \"three days two nights\", \"four days three nights\", \"five days four nights\", \"six days five nights\", \"seven days six nights\",\n",
        "    \"eight days seven nights\", \"nine days eight nights\", \"ten days nine nights\", \"eleven days ten nights\", \"twelve days eleven nights\", \"thirteen days twelve nights\",\n",
        "    \"fourteen days thirteen nights\", \"fifteen days fourteen nights\", \"sixteen days fifteen nights\", \"seventeen days sixteen nights\", \"eighteen days seventeen nights\",\n",
        "    \"nineteen days eighteen nights\", \"twenty days nineteen nights\", \"twenty-one days twenty nights\", \"twenty-two days twenty-one nights\", \"twenty-three days twenty-two nights\",\n",
        "    \"twenty-four days twenty-three nights\", \"twenty-five days twenty-four nights\", \"twenty-six days twenty-five nights\", \"twenty-seven days twenty-six nights\",\n",
        "    \"twenty-eight days twenty-seven nights\", \"twenty-nine days twenty-eight nights\", \"thirty days twenty-nine nights\", \"thirty-one days thirty nights\",\n",
        "    \"thirty-two days thirty-one nights\", \"thirty-three days thirty-two nights\", \"thirty-four days thirty-three nights\", \"thirty-five days thirty-four nights\",\n",
        "    \"thirty-six days thirty-five nights\", \"thirty-seven days thirty-six nights\", \"thirty-eight days thirty-seven nights\", \"thirty-nine days thirty-eight nights\",\n",
        "    \"forty days thirty-nine nights\", \"forty-one days forty nights\", \"forty-two days forty-one nights\", \"forty-three days forty-two nights\", \"forty-four days forty-three nights\",\n",
        "    \"forty-five days forty-four nights\", \"forty-six days forty-five nights\", \"forty-seven days forty-six nights\", \"forty-eight days forty-seven nights\", \"forty-nine days forty-eight nights\",\n",
        "    \"one hour\", \"two hours\", \"three hours\", \"four hours\", \"five hours\", \"six hours\", \"seven hours\", \"eight hours\", \"nine hours\", \"ten hours\",\n",
        "    \"eleven hours\", \"twelve hours\", \"thirteen hours\", \"fourteen hours\", \"fifteen hours\", \"sixteen hours\", \"seventeen hours\", \"eighteen hours\", \"nineteen hours\", \"twenty hours\",\n",
        "    \"twenty-one hours\", \"twenty-two hours\", \"twenty-three hours\", \"twenty-four hours\", \"one minute\", \"two minutes\", \"three minutes\", \"four minutes\", \"five minutes\",\n",
        "    \"ten minutes\", \"fifteen minutes\", \"twenty minutes\", \"thirty minutes\", \"one second\", \"two seconds\", \"three seconds\", \"four seconds\", \"five seconds\"\n",
        "]\n",
        "  return random.choice(time_list)\n",
        "\n",
        "def generate_date():\n",
        "  date_list =[\n",
        "    \"first of january\", \"second of february\", \"third of march\", \"fourth of april\", \"fifth of may\", \"sixth of june\",\n",
        "    \"seventh of july\", \"eighth of august\", \"ninth of september\", \"tenth of october\", \"eleventh of november\",\n",
        "    \"twelfth of december\", \"thirteenth of january\", \"fourteenth of february\", \"fifteenth of march\", \"sixteenth of april\",\n",
        "    \"seventeenth of may\", \"eighteenth of june\", \"nineteenth of july\", \"twentieth of august\", \"twenty-first of september\",\n",
        "    \"twenty-second of october\", \"twenty-third of november\", \"twenty-fourth of december\", \"twenty-fifth of january\",\n",
        "    \"twenty-sixth of february\", \"twenty-seventh of march\", \"twenty-eighth of april\", \"twenty-ninth of may\",\n",
        "    \"thirtieth of june\", \"thirty-first of july\", \"first of august\", \"second of september\", \"third of october\",\n",
        "    \"fourth of november\", \"fifth of december\", \"sixth of january\", \"seventh of february\", \"eighth of march\",\n",
        "    \"ninth of april\", \"tenth of may\", \"eleventh of june\", \"twelfth of july\", \"thirteenth of august\", \"fourteenth of september\",\n",
        "    \"fifteenth of october\", \"sixteenth of november\", \"seventeenth of december\", \"eighteenth of january\", \"nineteenth of february\",\n",
        "    \"1 january\", \"2 february\", \"3 march\", \"4 april\", \"5 may\", \"6 june\", \"7 july\", \"8 august\", \"9 september\", \"10 october\",\n",
        "    \"11 november\", \"12 december\", \"13 january\", \"14 february\", \"15 march\", \"16 april\", \"17 may\", \"18 june\", \"19 july\",\n",
        "    \"20 august\", \"21 september\", \"22 october\", \"23 november\", \"24 december\", \"25 january\", \"26 february\", \"27 march\",\n",
        "    \"28 april\", \"29 may\", \"30 june\", \"31 july\", \"1 august\", \"2 september\", \"3 october\", \"4 november\", \"5 december\",\n",
        "    \"6 january\", \"7 february\", \"8 march\", \"9 april\", \"10 may\", \"11 june\", \"12 july\", \"13 august\", \"14 september\",\n",
        "    \"15 october\", \"16 november\", \"17 december\", \"18 january\", \"19 february\", \"5 july\",\n",
        "    \"tomorrow\", \"day after tomorrow\", \"next week\", \"next month\", \"next year\", \"yesterday\", \"day before yesterday\", \"last week\", \"last month\", \"last year\",\n",
        "    \"new year's day\", \"valentine's day\", \"st. patrick's day\", \"easter sunday\", \"good friday\", \"halloween\", \"thanksgiving\",\n",
        "    \"christmas\", \"independence day\", \"labor day\", \"memorial day\", \"martin luther king jr. day\", \"presidents' day\",\n",
        "    \"veterans day\", \"columbus day\", \"juneteenth\", \"hanukkah\", \"ramadan\", \"diwali\", \"chinese new year\", \"mardi gras\",\n",
        "    \"earth day\", \"april fools' day\", \"cinco de mayo\", \"father's day\", \"mother's day\", \"international women's day\",\n",
        "    \"flag day\", \"patriot day\", \"national dog day\", \"black friday\", \"cyber monday\"\n",
        "]\n",
        "\n",
        "\n",
        "  return random.choice(date_list)\n",
        "\n",
        "tagss = []\n",
        "for i in range(len(seed_data[1])):\n",
        "  for j in seed_data[1][i]:\n",
        "    if j['label'] not in tagss:\n",
        "      tagss.append(j['label'])\n",
        "\n",
        "funcss = [generate_nric, generate_phone, generate_person, generate_org, generate_bank, generate_cardinal, generate_gpe, generate_car, generate_time, generate_email, generate_passport, generate_credit, generate_date]\n",
        "generate_dict = dict(zip(tagss, funcss))\n",
        "\n",
        "def data_to_prompt(data, tags):\n",
        "  prompt = \"\"\n",
        "  prompt = prompt + data + \". NER Tags = (\"\n",
        "  for tag in tags:\n",
        "    prompt += data[tag['start']:tag['end']] + \"-\" + tag['label']\n",
        "    prompt += \", \"\n",
        "  prompt = prompt + \")\"\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "WZwHvrvv_Xjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_lookup = []\n",
        "replaced_data = []\n",
        "\n",
        "for i in range(len(augmented_data)):\n",
        "\n",
        "  data = augmented_data[i].split('\\n')\n",
        "  tags = seed_data[1][i]\n",
        "\n",
        "  for sentence in data:\n",
        "    sentence = re.sub(r'[\",.]', \"\", sentence)\n",
        "    sentence = re.sub(r\"[']\", \"\", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = sentence[2:]\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    tag_list = {}\n",
        "    flag = True\n",
        "    for j in tags:\n",
        "\n",
        "      original_tag = seed_data[0][i][j['start']:j[\"end\"]]\n",
        "      label = j['label']\n",
        "      new_tag = generate_dict[label]()\n",
        "\n",
        "      if sentence.find(original_tag) != -1:\n",
        "        new_tag_x = \" \"+new_tag+\" \"\n",
        "        sentence = sentence.replace(original_tag, new_tag_x)\n",
        "        tag_list[label] = new_tag\n",
        "\n",
        "      else:\n",
        "        flag = False\n",
        "        manual_lookup.append(sentence)\n",
        "\n",
        "    if flag:\n",
        "      sentence = sentence.replace(\"  \", \" \")\n",
        "      replaced_data.append([sentence, tag_list])"
      ],
      "metadata": {
        "id": "wnLFphiY_lMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_indices(sentence, word):\n",
        "    start_index = sentence.find(word)\n",
        "    if start_index == -1:\n",
        "        return None, None\n",
        "    end_index = start_index + len(word)\n",
        "    return start_index, end_index"
      ],
      "metadata": {
        "id": "aOOXHiUu_oxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug2 = [[], []]\n",
        "for i in replaced_data:\n",
        "  aug2[0].append(i[0])\n",
        "  temp = []\n",
        "  for j in i[1]:\n",
        "    start, end = find_word_indices(i[0], i[1][j])\n",
        "    if start is not None and end is not None:\n",
        "      temp.append({\"start\": start, \"end\": end, \"label\": j})\n",
        "  aug2[1].append(temp)"
      ],
      "metadata": {
        "id": "3Gw8Kkd4BUqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sublist_indices(big, small):\n",
        "  start = small[0]\n",
        "  for i in range(len(big)):\n",
        "    if big[i] == start:\n",
        "      if big[i+len(small)-1] == small[-1]:\n",
        "        return [i, i+len(small)-1]\n",
        "  return -1"
      ],
      "metadata": {
        "id": "bYx0Uc-Nxu-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding noise\n",
        "speech_noises = [\n",
        "    \"(uh)\", \"(um)\", \"(er)\", \"(ah)\", \"(eh)\", \"(hmm)\", \"(mm-hmm)\", \"(uh-huh)\", \"(uh-uh)\", \"(oh)\",\n",
        "    \"(huh)\", \"(yeah)\", \"(like)\", \"(you know)\", \"(right)\", \"(so)\", \"(actually)\", \"(basically)\",\n",
        "    \"(literally)\", \"(I mean)\", \"(well)\", \"(kind of)\", \"(sort of)\", \"(uhm)\", \"(ohh)\", \"(ahh)\",\n",
        "    \"(umm)\", \"(err)\", \"(mmm)\", \"(tsk)\", \"(ahem)\", \"(gosh)\", \"(whoa)\", \"(wow)\", \"(oops)\", \"(uh-oh)\",\n",
        "    \"(phew)\", \"(eek)\", \"(shh)\", \"(huh-uh)\"\n",
        "]\n",
        "\n",
        "texts = []\n",
        "for i in range(len(aug2[0])):\n",
        "\n",
        "  if random.random() > 0.0001:\n",
        "    sent_split = aug2[0][i].split(\" \")\n",
        "    indices = []\n",
        "    indices = random.sample(range(0, len(sent_split)), 1)\n",
        "\n",
        "    for ind in indices:\n",
        "      tag_shift = []\n",
        "      for tag in range(len(aug2[1][i])):\n",
        "        try:\n",
        "          val = sublist_indices(sent_split, replaced_data[i][1][list(replaced_data[i][1].keys())[tag]].strip().split(\" \"))\n",
        "        except:\n",
        "          val = -1\n",
        "        if val != -1:\n",
        "          if val[0] == val[1]:\n",
        "            if ind <= val[0]:\n",
        "              tag_shift.append(1)\n",
        "            else:\n",
        "              tag_shift.append(0)\n",
        "          else:\n",
        "            if ind <= val[0]:\n",
        "              tag_shift.append(1)\n",
        "            elif ind > val[1]:\n",
        "              tag_shift.append(0)\n",
        "            elif ind > val[0] and ind <= val[1]:\n",
        "              tag_shift.append(2)\n",
        "        else:\n",
        "          tag_shift.append(-1)\n",
        "\n",
        "      if -1 not in tag_shift:\n",
        "        noise = random.sample(speech_noises, 1)[0]\n",
        "        sent_split.insert(ind, noise)\n",
        "        for j in range(len(tag_shift)):\n",
        "          if tag_shift[j] == 1:\n",
        "            aug2[1][i][j]['start'] += len(noise)+1\n",
        "            aug2[1][i][j]['end'] += len(noise)+1\n",
        "          elif tag_shift[j] == 2:\n",
        "            aug2[1][i][j]['end'] += len(noise)+1\n",
        "          elif tag_shift[j] == 0:\n",
        "            pass\n",
        "    texts.append(\" \".join(sent_split))\n",
        "  else:\n",
        "    texts.append(aug2[0][i])"
      ],
      "metadata": {
        "id": "gTZ_WScFJ673"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(texts)):\n",
        "  for j in range(len(aug2[1][i])):\n",
        "    start = aug2[1][i][j]['start']\n",
        "    end = aug2[1][i][j]['end']\n",
        "    label = aug2[1][i][j]['label']\n",
        "    if texts[i][end-1] == \" \":\n",
        "      aug2[1][i][j]['end'] = aug2[1][i][j]['end']- 1"
      ],
      "metadata": {
        "id": "eE9zlfnAAd0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug2[0] = texts"
      ],
      "metadata": {
        "id": "q-qP3pCdN0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(aug[0])):\n",
        "  if aug[1][i] == []:\n",
        "    aug2[0].append(aug[0][i])\n",
        "    aug2[1].append(aug[1][i])"
      ],
      "metadata": {
        "id": "-dFYKKz8b0Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined = list(zip(aug2[0], aug2[1]))\n",
        "random.shuffle(combined)\n",
        "\n",
        "aug2[0], aug2[1] = zip(*combined)\n",
        "aug2[0] = list(aug2[0])\n",
        "aug2[1] = list(aug2[1])"
      ],
      "metadata": {
        "id": "B2d-lGiwckW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('diverse.pkl', 'wb') as f:\n",
        "  pickle.dump(aug2, f)"
      ],
      "metadata": {
        "id": "Cf4-ustSC5_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Feisr_bVJs2e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}