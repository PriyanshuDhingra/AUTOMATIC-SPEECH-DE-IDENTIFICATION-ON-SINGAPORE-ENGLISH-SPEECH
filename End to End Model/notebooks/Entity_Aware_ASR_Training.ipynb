{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\priya\\SpokenNER\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import librosa\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOIGf4GmWf2p"
      },
      "outputs": [],
      "source": [
        "# Data preparation: Each data point is annotated using the start and end token in format [label_name] label [label_name]\n",
        "def prepare_data(jsonl_file, audio_folder):\n",
        "    data = []\n",
        "    with open(jsonl_file, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            item = json.loads(line)\n",
        "            text = item['text']\n",
        "            entities = item['entities']\n",
        "            # Insert entity tags\n",
        "            for start, end, label in reversed(entities):\n",
        "                text = text[:start] + f\"[{label}] \" + text[start:end] + f\" [{label}]\" + text[end:]\n",
        "            audio_file = f\"{audio_folder}/test{i+1}.wav\"\n",
        "            if not os.path.exists(audio_file):\n",
        "                print(f\"Warning: Audio file not found: {audio_file}\")\n",
        "                continue\n",
        "            data.append({\n",
        "                'audio': audio_file,\n",
        "                'text': text,\n",
        "            })\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWCRt3foqwG2",
        "outputId": "0244051b-370c-4550-bb92-c71152ba5cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb1C3pYUYga4"
      },
      "outputs": [],
      "source": [
        "# Custom dataset class\n",
        "class SpokenNERDataset(Dataset):\n",
        "    def __init__(self, data, processor):\n",
        "        self.data = data\n",
        "        self.processor = processor\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        audio_file = item['audio']\n",
        "        text = item['text']\n",
        "        # Load and process audio using librosa with sample rate as 16000\n",
        "        speech, _ = librosa.load(audio_file, sr=16000)\n",
        "        input_features = self.processor(speech, sampling_rate=16000, return_tensors=\"pt\").input_features # Extracting the audio features \n",
        "        labels = self.processor(text=text, return_tensors=\"pt\").input_ids  # Process text\n",
        "        return {\n",
        "            \"input_features\": input_features.squeeze(),\n",
        "            \"labels\": labels.squeeze(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-EV3rdEYiJs",
        "outputId": "b83229be-e14d-4abc-b752-ab0a646e9487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 137\n",
            "Test dataset size: 39\n",
            "Eval dataset size: 20\n"
          ]
        }
      ],
      "source": [
        "train_data = prepare_data(\"/content/Final_training_data.jsonl\", \"/content/Audio_Files_for_training\")\n",
        "test_data = prepare_data(\"/content/Final_testing_data.jsonl\", \"/content/Audio_Files_for_training\")\n",
        "eval_data = prepare_data(\"/content/Final_evaluation_data.jsonl\", \"/content/Audio_Files_for_training\")\n",
        "print(f\"Train dataset size: {len(train_data)}\")\n",
        "print(f\"Test dataset size: {len(test_data)}\")\n",
        "print(f\"Eval dataset size: {len(eval_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFLPXhR3Ykzd",
        "outputId": "4fd60218-2566-405c-f1a2-f703cd862c03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Using Whisper base model and processor\n",
        "model_name = \"openai/whisper-base\"\n",
        "processor = WhisperProcessor.from_pretrained(model_name)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "# Adding special tokens\n",
        "special_tokens = ['[PERSON]', '[PHONE]', '[DATE]', '[CARDINAL]', '[GPE]', '[LOC]', '[MONEY]', '[ORG]', '[EMAIL]', '[CREDIT_CARD]', '[BANK_ACCOUNT]', '[CAR_PLATE]', '[NRIC]', '[PASSPORT_NUM]', '[TIME]']\n",
        "processor.tokenizer.add_tokens(special_tokens)\n",
        "model.resize_token_embeddings(len(processor.tokenizer))\n",
        "\n",
        "train_dataset = SpokenNERDataset(train_data, processor)\n",
        "test_dataset = SpokenNERDataset(test_data, processor)\n",
        "eval_dataset = SpokenNERDataset(eval_data, processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVXByN1usjRp"
      },
      "outputs": [],
      "source": [
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9v9l-JkZnQT"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False,  \n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=3,\n",
        "    max_steps=500,\n",
        "    logging_steps=50,\n",
        "    save_steps=100,\n",
        "    eval_steps=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsWCSfKNZqg_"
      },
      "outputs": [],
      "source": [
        "# Data collator function\n",
        "def data_collator(features):\n",
        "    input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "    labels = [feature[\"labels\"] for feature in features]\n",
        "    batch = processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "    batch['labels'] = processor.tokenizer.pad({\"input_ids\": labels}, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "_HFLEmXNZvpM",
        "outputId": "d4eea024-0d81-48d2-f2e3-b3cf8e74180d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 05:16, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.496900</td>\n",
              "      <td>4.027322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.095700</td>\n",
              "      <td>4.561027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.034200</td>\n",
              "      <td>4.721690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.009400</td>\n",
              "      <td>4.882617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>4.885138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.2596944146156311, metrics={'train_runtime': 328.8844, 'train_samples_per_second': 6.081, 'train_steps_per_second': 1.52, 'total_flos': 1.2699587248128e+17, 'train_loss': 0.2596944146156311, 'epoch': 14.285714285714286})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWORP36faVr9",
        "outputId": "113bb948-8a77-4fe8-e32a-9d207b29fe09"
      },
      "outputs": [],
      "source": [
        "output_dir = \"./ner_model_v2\"\n",
        "model.save_pretrained(output_dir)\n",
        "processor.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvFLKGjDbuQ7",
        "outputId": "b3e34a43-89ce-4e8e-b394-9ac01ac39d69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "processor = WhisperProcessor.from_pretrained(output_dir)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(output_dir)\n",
        "\n",
        "def predict_entities(audio_file, processor, model):\n",
        "    speech, _ = librosa.load(audio_file, sr=16000)\n",
        "    input_features = processor(speech, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
        "\n",
        "    predicted_ids = model.generate(input_features)\n",
        "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)[0]\n",
        "\n",
        "    return transcription\n",
        "audio_file = \"Audio_Files_for_training/test1.wav\"\n",
        "transcription = predict_entities(audio_file, processor, model)\n",
        "print(f\"Transcription with entities: {transcription}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5Kh2WkIwIFa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
